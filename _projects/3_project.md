---
layout: page
title: Explanation and Trust in Automated Vehicles
description:
img: assets/img/kano1.png
importance: 3
category: work
related_publications: false
---

When it comes to automated vehicles (AVs), there are serious concerns about whether individuals will choose to employ them. One of the most central concerns is the lack of trust in AVs. In this project, we explored the possibility of using explanations of vehicle actions to help drivers build trust in automated vehicles. We conducted human-subject experiments in a driving simulator to investigate three research questions:
- How do the timing and the degree of AV autonomy influence the effectiveness of AV explanations?
- Does the driver’s age influence the relationship between AV explanations and the driver’s effort, anxiety, and trust?
- How does the modality of explanations influence their effectiveness?
<br />

<div class="row">
    <div class="col-sm mt-3 mt-md-0" style="width:50%;">
        {% include figure.liquid loading="eager" path="assets/img/kano1.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Kano model of customer satisfaction.
</div>

Our findings revealed that explanations provided before an AV acted were associated with higher trust in and preference for the AV. Additionally, the modality of explanations and the driver's age significantly moderated the relationship between explanation effectiveness and AV perceptions. These results have important implications for the adoption of AVs. To emphasize the importance of explanations in the context of AVs, I also synthesized a comprehensive literature survey paper, hoping to offer a holistic perspective on explanations and contribute to the advancement of the field. 
